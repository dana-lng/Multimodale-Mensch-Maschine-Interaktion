# ğŸ“ Multimodale Mensch-Maschine-Interaktion
---
## ğŸ‘©â€ğŸ’» Bearbeiterin
**Name:** Dana Lenzig  
**Matrikelnummer**: 57011  

---

## ğŸ“˜ Quellen

**All Birds Must Fly: The Experience of Multimodal Hands-free Gaming with Gaze and Nonverbal Voice Synchronization**

In dem Paper â€All Birds Must Fly: The Experience of Multimodal Hands-free Gaming with Gaze and Nonverbal Voice Synchronizatioyâ€œ untersuchten die Autorinnen und Autoren, ob Computerspiele vollstÃ¤ndig freihÃ¤ndig gesteuert werden kÃ¶nnen â€“ also nur durch Blickbewegungen und nichtverbale Stimmeingaben wie Summen. Ziel war es, eine intuitive und barrierefreie Steuerung zu entwickeln, die auch fÃ¼r Menschen mit kÃ¶rperlichen EinschrÃ¤nkungen geeignet ist.

Dazu wurde ein eigenes 2D-Spiel entwickelt, in dem ein Pinguin durch Blickrichtung gesteuert und durch Summen zum Springen gebracht wird. In einer ersten Studie mit 15 Personen ohne Behinderung wurde diese Steuerung mit Maus und Tastatur verglichen, in einer zweiten Studie testeten 10 Personen mit motorischen oder sprachlichen EinschrÃ¤nkungen die Methode.

Die Ergebnisse zeigten, dass die Blick- und Stimmeingabe zwar langsamer, aber fast genauso prÃ¤zise war wie die klassische Steuerung. Zudem wurde sie von den Teilnehmenden als spannender, unterhaltsamer und immersiver empfunden. Auch Personen mit Behinderungen konnten das Spiel erfolgreich bedienen.

Insgesamt zeigt die Studie, dass die Kombination aus Eye Tracking und nichtverbaler Stimmeingabe ein vielversprechender Ansatz fÃ¼r inklusive und freihÃ¤ndige Interaktionen ist, der sich Ã¼ber Spiele hinaus in weiteren digitalen Anwendungen einsetzen lÃ¤sst.

| <img src="img/SetUp.jpg" width="550"/> | <img src="img/Pinguin.jpg" width="200"/> |
|:-------------------------------------:|:-------------------------------------:|

Das Paper "Hands-Free Web Browsing: Enriching the User Experience with Gaze and Voice Modality" kombiniert Blicksteuerung und Spracheingabe, um Webseiten vollstÃ¤ndig freihÃ¤ndig bedienen zu kÃ¶nnen [Sengupta et al. 2018]. 
In einer Studie wurden typische Webaktionen wie Suchen, Scrollen und Link-Auswahl mit einem multimodalen Browser getestet, bei dem der Blick die Orientierung und die Sprache die BestÃ¤tigung Ã¼bernimmt. Im Vergleich zur reinen Sprach- oder Blicksteuerung zeigte sich die kombinierte Methode als deutlich effizienter (z.â€¯B. 70â€¯% schnellere Link-Auswahl). Besonders positiv bewertet wurde die MÃ¶glichkeit, flexibel zwischen den ModalitÃ¤ten zu wechseln â€“ etwa bei StÃ¶rungen oder MÃ¼digkeit.

Ã„hnlich wie in â€All Birds Must Fly: The Experience of Multimodal Hands-free Gaming with Gaze and Nonverbal Voice Synchronizatioyâ€œ wird deutlich, dass die Kombination beider Eingaben die SchwÃ¤chen der EinzelmodalitÃ¤ten ausgleicht und ein flÃ¼ssigeres, barrierefreies Nutzungserlebnis schafft. Beide Arbeiten zeigen, dass multimodale Steuerung nicht nur technisch machbar, sondern auch subjektiv angenehmer und inklusiver ist.

**Folgende Tabelle vergleicht die beiden vorgeschlagenen Systeme:**

| ModalitÃ¤t | Hedeshy et al. 2022 | Sengupta et al. 2018 |
| --- | --- | --- |
| Blick | Bewegung der Figur | Orientierung im Webbrower |
| (non-) verbale Steuerung | Springen | Auswahl im Webbrower |


---

## ğŸ§  AMITUDE-Modell
(A:) Ein 2D-Spiel namens â€œAll Birds Must Flyâ€, (U:) in dem vor allem Personen mit motorischen oder sprachlichen EinschrÃ¤nkungen (T:) einen Pinguin durch Level steuern. (M:) Dies geschieht Ã¼ber Blicksteuerung und nichtverbale Stimmeingabe (D:) mithilfe von Eye-Tracker und Mikrofon (E:) auf einem Laptop, (I:) wobei das System auf Eingaben reagiert und visuelles Feedback am Bildschirm gibt.

---

## ğŸ§® CARE-Modell
![Abbildung des CARE-Modells](img/CARE-Modell.png) 

---

## ğŸ§© CASE-Modell
Die Bewegungen des Pinguins werden CONCURRENT verarbeitet. .

---

## ğŸ”— Literaturverzeichnis
Ramin Hedeshy, Chandan Kumar, Mike Lauer, and Steffen Staab (2022).  
*All Birds Must Fly: The Experience of Multimodal Hands-free Gaming with Gaze and Nonverbal Voice Synchronization.*  
In: Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22).  
[https://doi.org/10.1145/3536221.3556593](https://doi.org/10.1145/3536221.3556593)
